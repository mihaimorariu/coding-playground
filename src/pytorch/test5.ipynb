{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
